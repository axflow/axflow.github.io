---
layout: ../../layouts/Blog.astro
title: Navigating the Shift
description: AI introduces a new way to build and iterate on products. In this non-deterministic world, engineering teams need new tools to systematically debug and improve their products.
authors:
  - nicholas
tags:
  - AI
  - LLM
  - Product Engineering
  - Probabalistic
published: 2023-12-13T00:00:00.000Z
---
import PostHeader from '../../components/PostHeader.astro'
import Link from '../../components/Link.astro';
export const components = {a: Link}

<PostHeader {...frontmatter} />

## From traditional software engineering to AI-everywhere development

Generative AI has taken the world by storm. ML has been around for decades, but recent breakthroughs in vision and text models have had an outsized impact on the landscape of tech.

Today, all it takes for an engineering team to introduce AI features into a product is a few API calls. The previous bar requiring  an in-house team of highly specialized ML engineers that trains models has been abstracted out.

The barrier to entry is lower than ever, and combined with the newly found quality that these APIs provide, we find ourselves in the largest technology revolution that we've seen in many years.

And so, just like software was [eating the world](https://a16z.com/why-software-is-eating-the-world/) in the 2010s, **AI is eating software** in the 2020s. Most companies have already introduced AI into their organization, and are aggressively exploring ways to leverage it to improve their products, reduce their costs, and make their workforce more productive.

This exciting change, like all change, comes with consequences. In particular, the role of SWEs is undergoing a significant transformation. Most engineers have experimented with these new APIs, on the job or on the side, but what they have yet to learn is that working with AI systems in production brings a unique set of challenges, and **requires a shift both in their mindset, and in their tools**.

Teams that are serious about shipping AI products go through two sequential phases:

- The capabilities phase, driven by the exciting possibilities of the positive cases
- The fear phase, driven by controlling the negative cases

These phases are separated by a very wide chasm (wider than nearly everyone thinks). Ever wondered why you see tons of *amazing* demos all over, but very few robust applications that are actually shipped yet? Self driving is the perfect example: we had [self-driving cars prototypes](https://www.youtube.com/watch?v=ntIczNQKfjQ) driving around in 1986, but only in 2022 did Cruise get the first permit to let autonomous cars drive within a major US city (San Francisco). Cruise had to go from proving that the car can go, to proving that it won't do anything wrong, and the latter problem is significantly harder than the first.

### The capabilities phase

We're right in the middle of this phase right now. Ever since GPT-3.5 came out, developers everywhere are coming out with amazing demos and ideas of what these APIs can do *sometimes*. They can generate code! They can create images! They can be specialized assistants!

A lot of the existing tooling that we've seen grow in popularity in the past year is optimizing for this phase. Frameworks, tools and APIs are all about what you can get the AI to do. This is important, but it's not sufficient for most companies to get to launching actual products.

### The fear phase

This is the big one. When I worked at Cruise, the most important metric for the company by far was Safety Critical Events, and we wanted that number to be as low as possible. Similarly, most people building customer support chatbots, nutrition assistants, code generators are not launching because they have to deal with all of the issues that come with non-determinism: hallucinations, unstable product experience,